{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yonhap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-406be19625ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdocnt0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdocnt1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtraining_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myonhap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ngram'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mwordfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yonhap' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "docnt0=0\n",
    "docnt1=0\n",
    "training_set = np.array(yonhap['ngram'])\n",
    "\n",
    "wordfreq=defaultdict(lambda:[0,0])\n",
    "for doc,point in training_set:\n",
    "    words=doc.split()\n",
    "    for word in words:\n",
    "        if updown=='up':\n",
    "            wordfreq[word][0]+=1\n",
    "        else:\n",
    "            wordfreq[word][1]+=1\n",
    "for key,(cnt1,cnt0) in wordfreq.items():\n",
    "        if cnt1>0:\n",
    "            docnt1+=1\n",
    "        if cnt0>0:\n",
    "            docnt0+=1\n",
    "print(wordfreq)\n",
    "\n",
    "k =0.5\n",
    "wordprobs = defaultdict(lambda : [0, 0])\n",
    "for key, (cnt1, cnt0) in wordfreq.items() :\n",
    "    wordprobs[key][0] = (cnt1 + k) / (docnt1 + 2*k)\n",
    "    wordprobs[key][1] = (cnt0 + k) / (docnt0 + 2*k)\n",
    "    \n",
    "print(wordprobs) \n",
    "\n",
    "doc = \"free lottery\"\n",
    "tokens = doc.split()\n",
    "log_prob1 = log_prob0 = 0.0\n",
    "for word, (prob1, prob0) in wordprobs.items():\n",
    "    if word in tokens:\n",
    "        log_prob1 += math.log(prob1)\n",
    "        log_prob0 += math.log(prob0)\n",
    "    else:\n",
    "        log_prob1 += math.log(1.0 - prob1)\n",
    "        log_prob0 += math.log(1.0 - prob0)\n",
    "log_prob1 += math.log(docnt1/len(wordfreq))\n",
    "log_prob0 += math.log(docnt0/len(wordfreq))\n",
    "prob1 = math.exp(log_prob1)\n",
    "prob0 = math.exp(log_prob0)\n",
    "\n",
    "print(doc)\n",
    "print(\"pos확률 : {}%\".format(prob1 / (prob1 + prob0)*100))\n",
    "print(\"neg확률 : {}%\".format(prob0 / (prob1 + prob0)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yonhap= pd.read_csv(\"(최종)연합인포맥스_2005-2019_콜금리라벨까지.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "docnt0=0\n",
    "docnt1=0\n",
    "training_set = np.array(yonhap['ngram'],yonhap['updown'])\n",
    "wordfreq=defaultdict(lambda:[0,0])\n",
    "for doc in training_set:\n",
    "    words=doc.split()\n",
    "    for word in words:\n",
    "        if updown=='up':\n",
    "            wordfreq[word][0]+=1\n",
    "        else:\n",
    "            wordfreq[word][1]+=1\n",
    "for key,(cnt1,cnt0) in wordfreq.items():\n",
    "        if cnt1>0:\n",
    "            docnt1+=1\n",
    "        if cnt0>0:\n",
    "            docnt0+=1\n",
    "for field, possible_values in wordfreq.items():\n",
    "    print(field, possible_values)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function defaultdict.items>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59692"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yonhap[yonhap['updown']=='down'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46255"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yonhap[yonhap['updown']=='up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "listt.append(yonhap[yonhap['updown']=='up']['ngram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'국채/NNG;가격/NNG;fed/NNG;금리/NNG;인상/NNG마지막/NNG,날/NNG,뉴욕/NNG,금융시장/NNG,한산/NNG,거래/NNG,속/NNG,새해/NNG,준비/NNG,양상/NNG,보/VV,채권시장/NNG,축장/NNG,운영/NNG,원/NNG,물/NNG,시장/NNG,휴장/NNG,하/VV,주식시장/NNG,뉴욕/NNG,주가/NNG,마지막/NNG,거래/NNG,보합권/NNG,마감/NNG,하/VV,다우존스산업평균지수/NNG,포인트/NNG,내리/VV,거래/NNG,마감/NNG,하/VV,s&p/NNG,지수/NNG,포인트/NNG,내리/VV,장/NNG,마치/VV,나스닥/NNG,포인트/NNG,내리/VV,거래/NNG,마치/VV,다우존스산업평균지수/NNG,기준/NNG,상승/NNG,하/VV,s&p500/NNG,상승/NNG,하/VV,다우존스산업평균지수/NNG,상승/NNG,s&p500/NNG,상승/NNG,하/VV,점/NNG,감안/NNG,오/VV,상대적/VAX,주가/NNG,상승/NNG,더디/VA,평가/NNG,되/VV,나스닥/NNG,급등/NNG,엔/NNG,상승/NNG,그치/VV,채권시장/NNG,만기/NNG,국채/NNG,수익률/NNG,전/NNG,낮/VA,수준/NNG,거래/NNG,마감/NNG,하/VV,fed/NNG,fed/NNG,금리/NNG,연/VV,들/VV,인상/NNG,인플레이션/NNG,잘/MAG,제어/NNG,예상/NNG,만기/NNG,국채/NNG,수익률/NNG,전/NNG,소폭/MAG,낮/VA,수준/NNG,끝/NNG,나/VV,만기/NNG,국채/NNG,가격/NNG,fed/NNG,금리/NNG,인상/NNG,지속/NNG,최악/NNG,보/VV,내/VV,fed/NNG,점진적/VAX,금리/NNG,인상/NNG,단행/NNG,하/VV,fed/NNG,금리/NNG,인상/NNG,고용시장/NNG,동향/NNG,예의/NNG,주시/NNG,되/VV,같/VA,반면/NNG,고용창출/NNG,건수/NNG,넘/VV,호전/NNG,되/VV,fed/NNG,공격적/VAX,금리/NNG,인상/NNG,정책/NNG,지속/NNG,되/VV,가능성/NNG,크/VA,강조/NNG,하/VV,만기/NNG,국채/NNG,가격/NNG,포인트/NNG,오르/VV,가격/NNG,반/NNG,움직이/VV,수익률/NNG,떨어/VV,마치/VV,만기/NNG,국채/NNG,수익률/NNG,기록/NNG,만기/NNG,국채/NNG,가격/NNG,수익률/NNG,끝/NNG,나/VV,외환시장/NNG,달러/NNG,개장/NNG,엔/NNG,근처/NNG,하락/NNG,약세/NNG,나타나/VV,유로/NNG,약세/NNG,대해/VV,낙폭/NNG,축소/NNG,하/VV,유로/NNG,유로/NNG,최고/NNG,행진/NNG,지속/NNG,어렵/VA,예상/NNG,거래자/NNG,적극적/VAX,달러/NNG,되사/VV,급락/NNG,돌아/VV,늦/VA,달러/NNG,엔/NNG,대해/VV,달러/NNG,엔/NNG,움직이/VV,뉴욕/NNG,장/NNG,가격/NNG,엔/NNG,엔/NNG,하락/NNG,하/VV,유로/NNG,달러/NNG,대해/VV,유로/NNG,달러/NNG,거래/NNG,되/VV,뉴욕후장가격/NNG,달러/NNG,달러/NNG,급락/NNG,하/VV,달러/NNG,엔/NNG,대해/VV,하락/NNG,하/VV,유로/NNG,달러/NNG,대해/VV,상/NNG,승했/VA,뉴욕/NNG,앞두/VV,길/VA,유로/NNG,강세/NNG,나타나/VV,가운/NNG,유로/NNG,엔/NNG,대해/VV,급락/NNG,보/VV,달러/NNG,급락/NNG,보/VV,하/VV,새해/NNG,들/VV,거래자/NNG,복귀/NNG,하/VV,환율/NNG,방향/NNG,달라지/VV,있/VA,달러/NNG,되사/VV,현상/NNG,나타나/VV,덧붙이/VV,원유/NNG,시장/NNG,휴장/NNG,끝/NNG'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap['n']=yonhap['ngram'].apply(lambda x : str(x).count(';'))\n",
    "yonhap=yonhap[yonhap['n']>15]\n",
    "yonhap['t/f']=yonhap['updown'].apply(lambda x : x in ('up','down','neutrality'))\n",
    "yonhap=yonhap[yonhap['t/f']==True]\n",
    "yonhap=yonhap.drop('t/f',axis=1)\n",
    "down확률=len(yonhap[yonhap['updown']=='down'])/len(yonhap) \n",
    "up확률=len(yonhap[yonhap['updown']=='up'])/len(yonhap) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
