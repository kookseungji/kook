{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>롯데첨단소재</th>\n",
       "      <th>의왕</th>\n",
       "      <th>2019-09-11</th>\n",
       "      <th>17:32:52</th>\n",
       "      <th>35124818</th>\n",
       "      <th>김영신</th>\n",
       "      <th>ABS)AD팀(OA)</th>\n",
       "      <th>석식</th>\n",
       "      <th>배식구3(INTER)</th>\n",
       "      <th>5000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>롯데첨단소재</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>17:33:24</td>\n",
       "      <td>35129357</td>\n",
       "      <td>김익모</td>\n",
       "      <td>PC)EP컴파운드팀</td>\n",
       "      <td>석식</td>\n",
       "      <td>배식구4(INTER)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>롯데첨단소재</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>17:46:57</td>\n",
       "      <td>35122221</td>\n",
       "      <td>김준명</td>\n",
       "      <td>PC)AD1팀(TV)</td>\n",
       "      <td>석식</td>\n",
       "      <td>배식구3(INTER)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>롯데첨단소재</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>17:39:13</td>\n",
       "      <td>35132260</td>\n",
       "      <td>김혁진</td>\n",
       "      <td>마케팅지원팀</td>\n",
       "      <td>석식</td>\n",
       "      <td>배식구3(INTER)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>롯데첨단소재</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>17:41:57</td>\n",
       "      <td>35123852</td>\n",
       "      <td>김현철</td>\n",
       "      <td>칼라LAB</td>\n",
       "      <td>석식</td>\n",
       "      <td>배식구3(INTER)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>롯데첨단소재</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>17:45:15</td>\n",
       "      <td>35123840</td>\n",
       "      <td>민우</td>\n",
       "      <td>칼라LAB</td>\n",
       "      <td>석식</td>\n",
       "      <td>배식구6(라면)</td>\n",
       "      <td>4287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292474</th>\n",
       "      <td>삼성SDI</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>12:16:18</td>\n",
       "      <td>98161186</td>\n",
       "      <td>최민우</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중식</td>\n",
       "      <td>배식구2(KOREAN)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292475</th>\n",
       "      <td>삼성SDI</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>12:10:27</td>\n",
       "      <td>최신영</td>\n",
       "      <td>최신영</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중식</td>\n",
       "      <td>배식구2(KOREAN)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292476</th>\n",
       "      <td>삼성SDI</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>12:07:48</td>\n",
       "      <td>98160941</td>\n",
       "      <td>홍웅선</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중식</td>\n",
       "      <td>배식구3(INTER)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292477</th>\n",
       "      <td>삼성SDI</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>11:33:33</td>\n",
       "      <td>98180127</td>\n",
       "      <td>최준하</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중식</td>\n",
       "      <td>배식구1(KOREAN)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292478</th>\n",
       "      <td>삼성SDI</td>\n",
       "      <td>의왕</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>11:33:11</td>\n",
       "      <td>98159620</td>\n",
       "      <td>최영태</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중식</td>\n",
       "      <td>배식구3(INTER)</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292479 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        롯데첨단소재  의왕  2019-09-11  17:32:52  35124818  김영신  ABS)AD팀(OA)  석식  \\\n",
       "0       롯데첨단소재  의왕  2019-09-11  17:33:24  35129357  김익모   PC)EP컴파운드팀  석식   \n",
       "1       롯데첨단소재  의왕  2019-09-11  17:46:57  35122221  김준명  PC)AD1팀(TV)  석식   \n",
       "2       롯데첨단소재  의왕  2019-09-11  17:39:13  35132260  김혁진       마케팅지원팀  석식   \n",
       "3       롯데첨단소재  의왕  2019-09-11  17:41:57  35123852  김현철        칼라LAB  석식   \n",
       "4       롯데첨단소재  의왕  2019-09-11  17:45:15  35123840   민우        칼라LAB  석식   \n",
       "...        ...  ..         ...       ...       ...  ...          ...  ..   \n",
       "292474   삼성SDI  의왕  2020-05-08  12:16:18  98161186  최민우          NaN  중식   \n",
       "292475   삼성SDI  의왕  2020-05-08  12:10:27       최신영  최신영          NaN  중식   \n",
       "292476   삼성SDI  의왕  2020-05-08  12:07:48  98160941  홍웅선          NaN  중식   \n",
       "292477   삼성SDI  의왕  2020-05-08  11:33:33  98180127  최준하          NaN  중식   \n",
       "292478   삼성SDI  의왕  2020-05-08  11:33:11  98159620  최영태          NaN  중식   \n",
       "\n",
       "         배식구3(INTER)    5000  \n",
       "0        배식구4(INTER)  5000.0  \n",
       "1        배식구3(INTER)  5000.0  \n",
       "2        배식구3(INTER)  5000.0  \n",
       "3        배식구3(INTER)  5000.0  \n",
       "4           배식구6(라면)  4287.0  \n",
       "...              ...     ...  \n",
       "292474  배식구2(KOREAN)  5000.0  \n",
       "292475  배식구2(KOREAN)  5000.0  \n",
       "292476   배식구3(INTER)  5000.0  \n",
       "292477  배식구1(KOREAN)  5000.0  \n",
       "292478   배식구3(INTER)  5000.0  \n",
       "\n",
       "[292479 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('raw_data.csv')\n",
    "data=data[['롯데첨단소재', '2019-09-11', '석식', '배식구3(INTER)']]\n",
    "data.columns=['회사명', '식수일자',  '조식/중식/석식/야식', '식단구분']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data.groupby(['회사명','식수일자',  '조식/중식/석식/야식','식단구분']).count().reset_index()\n",
    "data['식단구분']=data['식단구분'].apply(lambda x : str(x).replace('김밥','라면'))\n",
    "data=data.rename(columns={'cnt':'식사인원'})\n",
    "data.sort_values('식수일자').reset_index().drop('index',axis=1).to_csv('의왕점.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('의왕점.csv',index_col=False)\n",
    "data=data[(data[ '조식/중식/석식/야식']=='중식')&(data['식단구분']=='KOREAN')].groupby('식수일자').sum().reset_index()\n",
    "data=data.rename(columns={'식사인원':'target'})\n",
    "data=data.rename(columns={'식수일자':'timestamp'})\n",
    "data['timestamp']=data['timestamp'].apply(lambda x:pd.to_datetime(x))\n",
    "data['dayofweek_mean']='.'\n",
    "data['dayofweek_median']='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "data1['weekday']=data1['timestamp'].apply(lambda x: calendar.weekday(x.year,x.month,x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['weekday']).median()\n",
    "def func(total):\n",
    "    if total['weekday']==0:\n",
    "        return 217\n",
    "    elif total['weekday']==1: \n",
    "        return 187\n",
    "    elif total['weekday']==2: \n",
    "        return 172\n",
    "    elif total['weekday']==3: \n",
    "        return 189\n",
    "    elif total['weekday']==4: \n",
    "        return 151\n",
    "    else:\n",
    "        return 0\n",
    "        pass \n",
    "    \n",
    "data1.dayofweek_median=data1.apply(func,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['weekday']).mean()\n",
    "def func(total):\n",
    "    if total['weekday']==0:\n",
    "        return 205\n",
    "    elif total['weekday']==1: \n",
    "        return 189\n",
    "    elif total['weekday']==2: \n",
    "        return 176\n",
    "    elif total['weekday']==3: \n",
    "        return 179\n",
    "    elif total['weekday']==4: \n",
    "        return 154\n",
    "    else:\n",
    "        return 0\n",
    "        pass \n",
    "    \n",
    "data1.dayofweek_mean=data1.apply(func,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과거 temperature    \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy={year}&obs=08&x=32&y=9'.format(year='2018'))  \n",
    "soup=BeautifulSoup(bam.text,'html.parser')\n",
    "content=soup.find_all('td')\n",
    "bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy={year}&obs=08&x=32&y=9'.format(year='2019'))  \n",
    "soup=BeautifulSoup(bam.text,'html.parser')\n",
    "content1=soup.find_all('td')\n",
    "bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy={year}&obs=08&x=32&y=9'.format(year='2020'))  \n",
    "soup=BeautifulSoup(bam.text,'html.parser')\n",
    "content2=soup.find_all('td')\n",
    "data['temperature']=data['timestamp'].apply(lambda x: content[3+(x.day-1)*13+x.month].text if x.year==2018 else (content1[3+(x.day-1)*13+x.month].text if x.year==2019 else content2[3+(x.day-1)*13+x.month].text ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def abnormal(prev):\n",
    "    try: \n",
    "        if (prev['timestamp'].month in [6,7,8]) & (float(prev['temperature'])>=28):\n",
    "            return 1\n",
    "        elif (prev['timestamp'].month in [9,10,11]) & (float(prev['temperature'])>=5):\n",
    "            return 1\n",
    "        elif (prev['timestamp'].month in [12,1,2]) & (float(prev['temperature'])<=-5):\n",
    "            return 1\n",
    "        elif (prev['timestamp'].month in [3,4,5]) & (float(prev['temperature'])<=5):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        prev['temperature']==np.nan\n",
    "            \n",
    "data['abnormal']=data.apply(abnormal,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2018&obs=21&x=18&y=7')  \n",
    "soup=BeautifulSoup(bam.text,'html.parser')\n",
    "content=soup.find_all('td')\n",
    "bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2019&obs=21&x=18&y=7')  \n",
    "soup=BeautifulSoup(bam.text,'html.parser')\n",
    "content1=soup.find_all('td')\n",
    "bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2020&obs=21&x=18&y=7')  \n",
    "soup=BeautifulSoup(bam.text,'html.parser')\n",
    "content2=soup.find_all('td')\n",
    "data['rainfall']=data['timestamp'].apply(lambda x: content[3+(x.day-1)*13+x.month].text if x.year==2018 else (content1[3+(x.day-1)*13+x.month].text if x.year==2019 else content2[3+(x.day-1)*13+x.month].text ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /usr/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "holiday=[]\n",
    "date=['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "for j in range(2018,2021):\n",
    "    for i in range(len(date)):\n",
    "        url='http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo?solYear={year}&solMonth={date}&ServiceKey=J%2FYE3sN528TkttbFXsmjXDfVrpZyKNjduV1r%2FcUxAfJ7wHnrjO2F5zzkJx2JvBHsmuNstAVe%2B5n6fS2dNgcKvQ%3D%3D'.format(year=str(j),date=date[i])\n",
    "        resp=requests.get(url)\n",
    "        soup=BeautifulSoup(resp.content)\n",
    "        Text=soup.find_all('locdate')\n",
    "        for i in range(len(Text)):\n",
    "            holiday.append(pd.to_datetime(Text[i].text)) \n",
    "            \n",
    "def holiday1(x):\n",
    "    if (x in holiday)==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "from datetime import timedelta    \n",
    "def before_holiday(data):\n",
    "    if data['holiday']==1:\n",
    "        return 0\n",
    "    elif data['timestamp']+timedelta(days=1) in holiday:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "def after_holiday(data):\n",
    "    if data['holiday']==1:\n",
    "        return 0\n",
    "    elif data['timestamp']+timedelta(days=-1) in holiday:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "        \n",
    "data1['holiday']=data1['timestamp'].apply(lambda x: holiday1(x))\n",
    "data1['before_holiday']=data1.apply(before_holiday,axis=1)\n",
    "data1['after_holiday']=data1.apply(after_holiday,axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-25ec12be59cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mmake_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-25ec12be59cf>\u001b[0m in \u001b[0;36mmake_df\u001b[0;34m(prev, n)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 미래\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-25ec12be59cf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 미래\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "def z_score_normalize(lst):\n",
    "    normalized = []\n",
    "    for value in lst:\n",
    "        normalized_num = (value - np.mean(lst)) / np.std(lst)\n",
    "        normalized.append(normalized_num)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "#prev=06/15 까지 채운 데이터프레임 \n",
    "##오늘(6월 16일)부터 10일 간의 데이터 채워지는 함수입니다   -----> 까지 채우는 걸로 바꿔야ㅇㅇ\n",
    "def make_df(prev,n):\n",
    "    prev['timestamp']=pd.to_datetime(prev['timestamp'])\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    # 과거 rainfall\n",
    "    bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2020&obs=21&x=18&y=7')  \n",
    "    soup=BeautifulSoup(bam.text,'html.parser')\n",
    "    content=soup.find_all('td')\n",
    "    month=[i.month for i in prev[prev['rainfall'].notnull()]['timestamp']]\n",
    "    day=[i.day for i in prev[prev['rainfall'].notnull()]['timestamp']]\n",
    "    prev.loc[prev['rainfall'].notnull(),'rainfall']=[i.replace(\"\\xa0\", \"0\") if i =='\\xa0' else i for i in [content[3+(day[u]-1)*13+month[u]].text for u in range(len(month))]]   \n",
    "    \n",
    "# 과거 temperature    \n",
    "    bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2020&obs=08&x=25&y=4')  \n",
    "    soup=BeautifulSoup(bam.text,'html.parser')\n",
    "    content=soup.find_all('td')\n",
    "    month=[i.month for i in prev[prev['temperature'].notnull()]['timestamp']]\n",
    "    day=[i.day for i in prev[prev['temperature'].notnull()]['timestamp']]\n",
    "    prev.loc[prev['temperature'].notnull(),'temperature']=[float(i) for i in [content[3+(day[u]-1)*13+month[u]].text for u in range(len(month))]]\n",
    "    \n",
    "# 미래    \n",
    "#     bam=requests.get('https://m.weather.naver.com/')  \n",
    "#     soup=BeautifulSoup(bam.text,'html.parser')\n",
    "#     content=soup.find_all('div',{'class':'weather'})\n",
    "#     prob=[]\n",
    "#     for i in range(n):\n",
    "#         prob.append(content[i].find_all('span',{'class':'percent'})[0].text[:-1]) \n",
    "\n",
    "#     bam=requests.get('https://m.weather.naver.com/')\n",
    "#     soup=BeautifulSoup(bam.text,'html.parser')\n",
    "#     content=soup.find_all('div',{'class':'weekly_item_temperature'})\n",
    "#     temp=[]\n",
    "#     for i in range(n):\n",
    "#         temp.append(content[i].find_all('span')[3].text[6:8]) # 06/17~06/27\n",
    "\n",
    "    import numpy as np\n",
    "    from datetime import timedelta\n",
    "    num=[]\n",
    "    for i in range(1,n):\n",
    "        num.append(int(prev.index[-1]+i))\n",
    "\n",
    "    for i in range(n-1):    \n",
    "        prev.loc[num[i]]=np.nan\n",
    "        prev.loc[num[i],'timestamp']=prev.loc[num[i]-1,'timestamp']+timedelta(days=1)\n",
    "        prev.loc[num[i],'day_cos']=prev.loc[num[i]-7,'day_cos']\n",
    "        prev.loc[num[i],'day_sin']=prev.loc[num[i]-7,'day_sin']\n",
    "        prev.loc[num[i],'weekday']=prev.loc[num[i]-7,'weekday']\n",
    "        prev.loc[num[i],'dayofweek_median']=prev.loc[num[i]-7,'dayofweek_median']\n",
    "        prev.loc[num[i],'dayofweek_mean']=prev.loc[num[i]-7,'dayofweek_mean']\n",
    "          \n",
    "#     from datetime import datetime\n",
    "#     for i in range(n):\n",
    "#         prev.loc[prev['timestamp']==datetime.strptime(datetime.today().strftime(\"%Y-%m-%d\"),\"%Y-%m-%d\")+timedelta(days=i),'temperature']=temp[i] \n",
    "#         prev.loc[prev['timestamp']==datetime.strptime(datetime.today().strftime(\"%Y-%m-%d\"),\"%Y-%m-%d\")+timedelta(days=i),'rain_prob']=int(prob[i])*0.1\n",
    "    \n",
    "    url='http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo?solYear={year}&solMonth={date}&ServiceKey=J%2FYE3sN528TkttbFXsmjXDfVrpZyKNjduV1r%2FcUxAfJ7wHnrjO2F5zzkJx2JvBHsmuNstAVe%2B5n6fS2dNgcKvQ%3D%3D'.format(year=str((prev.loc[prev.index[-1],'timestamp']).year),date=str(prev.loc[prev.index[-1],'timestamp'].month))\n",
    "    resp=requests.get(url)\n",
    "    soup=BeautifulSoup(resp.content)\n",
    "    Text=soup.find_all('locdate')\n",
    "    holiday=[]\n",
    "    for i in range(len(Text)):\n",
    "        holiday.append(pd.to_datetime(Text[i].text))  \n",
    "    def holiday1(prev):\n",
    "        if prev['timestamp'] in holiday:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    def before_holiday(prev):\n",
    "        if prev['holiday']==1:\n",
    "            return 0\n",
    "        elif prev['timestamp']+timedelta(days=1) in holiday:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0    \n",
    "\n",
    "    def after_holiday(prev):\n",
    "        if prev['holiday']==1:\n",
    "            return 0\n",
    "        elif prev['timestamp']+timedelta(days=-1) in holiday:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 \n",
    "    def abnormal(prev):\n",
    "        try: \n",
    "            if (prev['timestamp'].month in [6,7,8]) & (int(prev['temperature'])>=28):\n",
    "                return 1\n",
    "            elif (prev['timestamp'].month in [9,10,11]) & (int(prev['temperature'])>=5):\n",
    "                return 1\n",
    "            elif (prev['timestamp'].month in [12,1,2]) & (int(prev['temperature'])<=-5):\n",
    "                return 1\n",
    "            elif (prev['timestamp'].month in [3,4,5]) & (int(prev['temperature'])<=5):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        except:\n",
    "            prev['temperature']==np.nan\n",
    "            \n",
    "    prev['abnormal']=prev.apply(abnormal,axis=1)         \n",
    "    prev['holiday']=prev.apply(holiday1,axis=1)\n",
    "    prev['before_holiday']=prev.apply(before_holiday,axis=1)\n",
    "    prev['after_holiday']=prev.apply(after_holiday,axis=1)   \n",
    "    \n",
    "    bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2020&obs=21&x=18&y=7')  # 과거 rainfall rain_prob\n",
    "    soup=BeautifulSoup(bam.text,'html.parser')\n",
    "    content=soup.find_all('td')\n",
    "    month=[i.month for i in prev[prev['rainfall'].notnull()]['timestamp']]\n",
    "    day=[i.day for i in prev[prev['rainfall'].notnull()]['timestamp']]\n",
    "    prev.loc[prev['rainfall'].notnull(),'rainfall']=[i.replace(\"\\xa0\", \"0\") if i =='\\xa0' else i for i in [content[3+(day[u]-1)*13+month[u]].text for u in range(len(month))]]   \n",
    "#     prev.loc[(prev['rain_prob'].notnull())&(prev['rainfall']=='0'),'rain_prob']=0\n",
    "    \n",
    "    bam=requests.get('https://www.weather.go.kr/weather/climate/past_table.jsp?stn=108&yy=2020&obs=08&x=25&y=4')  # 과거 temperature\n",
    "    soup=BeautifulSoup(bam.text,'html.parser')\n",
    "    content=soup.find_all('td')\n",
    "    month=[i.month for i in prev[prev['temperature'].notnull()]['timestamp']]\n",
    "    day=[i.day for i in prev[prev['temperature'].notnull()]['timestamp']]\n",
    "    prev.loc[prev['temperature'].notnull(),'temperature']=[i for i in [content[3+(day[u]-1)*13+month[u]].text for u in range(len(month))]]\n",
    "   \n",
    "#     if float(prev.loc[prev['abnormal'].isnull(),'temperature'])>=28:\n",
    "#         prev.loc[prev['abnormal'].isnull(),'abnormal']=1\n",
    "#     else:\n",
    "#         prev.loc[prev['abnormal'].isnull(),'abnormal']=0\n",
    "    \n",
    "    return prev    \n",
    "\n",
    "\n",
    "make_df(data,10).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "start_date='2018-12-11'\n",
    "end_date='2020-10-10'\n",
    "daterange = pd.date_range(start_date, end_date)\n",
    "l=[]\n",
    "for single_date in daterange:\n",
    "    l.append(single_date.strftime(\"%Y-%m-%d\"))\n",
    "l=pd.Series(l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame(l,columns={'timestamp'})\n",
    "d['timestamp']=d['timestamp'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp']=data['timestamp'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.merge(data,d,on='timestamp',how='right')\n",
    "data1=data1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[(data1.target==0)&(data1.weekday.isin([1,2,3,4]))&(data1.holiday==0)]['holiday'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6019517727800754,\n",
       " 0.37558447072504236,\n",
       " 0.7313045168115228,\n",
       " 0.8822160515148781,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.119362748905865,\n",
       " 0.5049372147564898,\n",
       " 0.14921716867000934,\n",
       " 0.5372754007643517,\n",
       " 0.11687898266214747,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9900100048744177,\n",
       " 0.23545233135764096,\n",
       " -0.10948831939288554,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7097457261396148,\n",
       " 1.2487154929373125,\n",
       " 0.2677905173655028,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1301421442418191,\n",
       " 0.8390984701710623,\n",
       " 0.5803929821081675,\n",
       " 0.688186935467707,\n",
       " 1.0654657722260954,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.5074209810002073,\n",
       " 1.2918330742811284,\n",
       " 0.23545233135764096,\n",
       " 0.8714366561789242,\n",
       " 0.1815553546778712,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8283190748351084,\n",
       " 0.5372754007643517,\n",
       " -0.2603998540962409,\n",
       " 0.2031141453497791,\n",
       " 0.4294814474048121,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7959808888272465,\n",
       " 0.9468924235306019,\n",
       " 0.91455423752274,\n",
       " 1.1301421442418191,\n",
       " -0.2603998540962409,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.33246688938122654,\n",
       " -0.3035174354400567,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9900100048744177,\n",
       " 0.6666281447957991,\n",
       " 0.8067602841632004,\n",
       " 0.8822160515148781,\n",
       " 0.10609958732619353,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4319652136485297,\n",
       " 1.0978039582339572,\n",
       " 0.3109080987093186,\n",
       " 0.903774842186786,\n",
       " 0.019864424638561896,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7744220981553386,\n",
       " 0.2677905173655028,\n",
       " 0.33246688938122654,\n",
       " 0.45104023807672,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0546863768901413,\n",
       " 0.5911723774441214,\n",
       " 0.3863638660609963,\n",
       " 0.7528633074834307,\n",
       " 0.05220261064642376,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.367288841632806,\n",
       " 0.9684512142025098,\n",
       " 0.4294814474048121,\n",
       " 0.08454079665428561,\n",
       " 0.6127311681160293,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1301421442418191,\n",
       " 0.903774842186786,\n",
       " 0.7420839121474767,\n",
       " 0.5911723774441214,\n",
       " 0.27856991270145676,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0331275862182334,\n",
       " 0.8067602841632004,\n",
       " 0.2677905173655028,\n",
       " 0.07376140131833166,\n",
       " 0.35402568005313445,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.3133918649530363,\n",
       " 0.44026084274076605,\n",
       " 0.5911723774441214,\n",
       " 0.6774075401317531,\n",
       " 0.37558447072504236,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4104064229766218,\n",
       " 0.7205251214755688,\n",
       " 0.4941578194205358,\n",
       " 0.41870205206885813,\n",
       " 0.7636427028193846,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9792306095384637,\n",
       " 0.6019517727800754,\n",
       " 0.44026084274076605,\n",
       " 0.3863638660609963,\n",
       " 0.1815553546778712,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0654657722260954,\n",
       " 0.46181963341267396,\n",
       " 0.5049372147564898,\n",
       " -1.2844424110118664,\n",
       " -0.012473761369299962,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0439069815541875,\n",
       " 2.9734187466899447,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -0.5837817141748595,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.119362748905865,\n",
       " 0.7852014934912925,\n",
       " 0.5803929821081675,\n",
       " 0.27856991270145676,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.140921539577773,\n",
       " 0.8175396794991544,\n",
       " 0.46181963341267396,\n",
       " 0.17077595934191725,\n",
       " 0.24623172669359492,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0223481908822796,\n",
       " 0.4941578194205358,\n",
       " 0.6127311681160293,\n",
       " 0.19233475001382513,\n",
       " 0.14921716867000934,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.140921539577773,\n",
       " 1.0223481908822796,\n",
       " 0.6342899587879373,\n",
       " -0.12026771472883949,\n",
       " 0.07376140131833166,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8822160515148781,\n",
       " 0.5157166100924437,\n",
       " 0.9468924235306019,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2594948882732664,\n",
       " 0.9792306095384637,\n",
       " 0.6235105634519833,\n",
       " 0.6342899587879373,\n",
       " 0.5372754007643517,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7205251214755688,\n",
       " 0.40792265673290423,\n",
       " 0.7636427028193846,\n",
       " 0.9900100048744177,\n",
       " 0.3216874940452726,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4211858183125756,\n",
       " 0.2677905173655028,\n",
       " 0.5588341914362596,\n",
       " 0.48337842408458187,\n",
       " 0.45104023807672,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1948185162575429,\n",
       " 0.9468924235306019,\n",
       " 0.5372754007643517,\n",
       " 0.6774075401317531,\n",
       " 0.2893493080374107,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8390984701710623,\n",
       " 0.688186935467707,\n",
       " 0.35402568005313445,\n",
       " 0.4725990287486279,\n",
       " 0.03064381997451585,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1085833535699112,\n",
       " 0.8067602841632004,\n",
       " 0.33246688938122654,\n",
       " 0.4941578194205358,\n",
       " -0.04481194737716182,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.119362748905865,\n",
       " 0.8822160515148781,\n",
       " 0.5480547961003056,\n",
       " 1.1840391209215888,\n",
       " 0.5157166100924437,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7744220981553386,\n",
       " 0.2677905173655028,\n",
       " 0.10609958732619353,\n",
       " 0.8175396794991544,\n",
       " 0.12765837799810142,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2918330742811284,\n",
       " 0.46181963341267396,\n",
       " 0.5264960054283977,\n",
       " 0.17077595934191725,\n",
       " 0.3109080987093186,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8606572608429702,\n",
       " 0.3109080987093186,\n",
       " 0.48337842408458187,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2271567022654046,\n",
       " 0.5480547961003056,\n",
       " 0.8283190748351084,\n",
       " 0.6342899587879373,\n",
       " 0.33246688938122654,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7313045168115228,\n",
       " 0.5264960054283977,\n",
       " 0.8175396794991544,\n",
       " 0.8283190748351084,\n",
       " 0.33246688938122654,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1948185162575429,\n",
       " 0.6774075401317531,\n",
       " 0.3863638660609963,\n",
       " 0.8283190748351084,\n",
       " 0.3971432613969503,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9900100048744177,\n",
       " 0.25701112202954884,\n",
       " -0.04481194737716182,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4319652136485297,\n",
       " 0.8714366561789242,\n",
       " 0.6666281447957991,\n",
       " 0.30012870337336467,\n",
       " 0.1599965640059633,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.3026124696170822,\n",
       " 0.7097457261396148,\n",
       " 0.6774075401317531,\n",
       " 0.44026084274076605,\n",
       " 0.0414232153104698,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.4941578194205358,\n",
       " 0.7205251214755688,\n",
       " 0.45104023807672,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -0.8640459929096622,\n",
       " -1.2736630156759126,\n",
       " 0.6019517727800754,\n",
       " -1.2952218063478205,\n",
       " 0.8714366561789242,\n",
       " 0.6774075401317531,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9684512142025098,\n",
       " 0.2677905173655028,\n",
       " 0.6774075401317531,\n",
       " 0.224672936021687,\n",
       " 0.12765837799810142,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8390984701710623,\n",
       " 0.2893493080374107,\n",
       " 0.5049372147564898,\n",
       " 0.8714366561789242,\n",
       " 0.3971432613969503,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0546863768901413,\n",
       " 0.44026084274076605,\n",
       " 0.6342899587879373,\n",
       " 1.0439069815541875,\n",
       " 0.5049372147564898,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0654657722260954,\n",
       " 0.3109080987093186,\n",
       " 0.41870205206885813,\n",
       " 0.8498778655070163,\n",
       " 0.5480547961003056,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9900100048744177,\n",
       " 0.6127311681160293,\n",
       " 1.0223481908822796,\n",
       " 0.688186935467707,\n",
       " 0.35402568005313445,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8606572608429702,\n",
       " 0.7313045168115228,\n",
       " 0.688186935467707,\n",
       " 0.5911723774441214,\n",
       " 0.33246688938122654,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4319652136485297,\n",
       " 0.903774842186786,\n",
       " 0.7313045168115228,\n",
       " 0.41870205206885813,\n",
       " 0.6666281447957991,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2379360976013587,\n",
       " 0.9576718188665558,\n",
       " 1.1301421442418191,\n",
       " 1.1840391209215888,\n",
       " 0.3863638660609963,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6558487494598452,\n",
       " 0.7097457261396148,\n",
       " 0.91455423752274,\n",
       " 0.7097457261396148,\n",
       " 0.14921716867000934,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0115687955463255,\n",
       " 0.41870205206885813,\n",
       " 0.10609958732619353,\n",
       " 0.6019517727800754,\n",
       " 0.17077595934191725,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.4941578194205358,\n",
       " 0.2031141453497791,\n",
       " -1.2952218063478205,\n",
       " 0.5372754007643517,\n",
       " 0.3648050753890884,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -0.22806166808837902,\n",
       " 0.37558447072504236,\n",
       " -1.2952218063478205,\n",
       " 0.7744220981553386,\n",
       " 0.3971432613969503,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0870245628980033,\n",
       " 0.8822160515148781,\n",
       " 0.9900100048744177,\n",
       " 0.5696135867722135,\n",
       " 0.3216874940452726,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0978039582339572,\n",
       " 0.8067602841632004,\n",
       " 0.40792265673290423,\n",
       " 1.0439069815541875,\n",
       " 0.3863638660609963,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9684512142025098,\n",
       " 0.46181963341267396,\n",
       " 1.3349506556249442,\n",
       " 0.05220261064642376,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6235105634519833,\n",
       " 1.0115687955463255,\n",
       " 0.688186935467707,\n",
       " 0.23545233135764096,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6774075401317531,\n",
       " 0.8067602841632004,\n",
       " 0.7528633074834307,\n",
       " 0.40792265673290423,\n",
       " 0.05220261064642376,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4319652136485297,\n",
       " 1.1085833535699112,\n",
       " 0.7852014934912925,\n",
       " 0.6774075401317531,\n",
       " 0.6342899587879373,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2594948882732664,\n",
       " 0.8929954468508321,\n",
       " 0.17077595934191725,\n",
       " 1.0439069815541875,\n",
       " 0.6666281447957991,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.367288841632806,\n",
       " 0.7528633074834307,\n",
       " 1.140921539577773,\n",
       " 1.2055979115934967,\n",
       " 0.5049372147564898,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0439069815541875,\n",
       " 1.6152149343597468,\n",
       " 1.5828767483518849,\n",
       " 1.2702742836092205,\n",
       " 1.7230088877192864,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4211858183125756,\n",
       " 1.6044355390237928,\n",
       " 1.9601555851102732,\n",
       " 0.91455423752274,\n",
       " 0.925333632858694,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -0.691575667534399,\n",
       " 1.0762451675620492,\n",
       " 1.2487154929373125,\n",
       " 1.6152149343597468,\n",
       " 0.91455423752274,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2487154929373125,\n",
       " 1.5074209810002073,\n",
       " 1.140921539577773,\n",
       " 1.6259943296957007,\n",
       " 1.345730050960898,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.4643033996563914,\n",
       " 1.2810536789451743,\n",
       " 2.1326259104855367,\n",
       " 1.5182003763361611,\n",
       " 0.7636427028193846,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2379360976013587,\n",
       " 1.4427446089844835,\n",
       " 0.6342899587879373,\n",
       " 1.0762451675620492,\n",
       " 0.5911723774441214,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1301421442418191,\n",
       " 0.23545233135764096,\n",
       " -1.2952218063478205,\n",
       " 1.4643033996563914,\n",
       " 0.9900100048744177,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.903774842186786,\n",
       " 1.3888476323047139,\n",
       " 0.35402568005313445,\n",
       " 0.7420839121474767,\n",
       " 0.688186935467707,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.5289797716721152,\n",
       " 1.2379360976013587,\n",
       " 0.4294814474048121,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.3241712602889901,\n",
       " 0.925333632858694,\n",
       " 0.3432462847171805,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1301421442418191,\n",
       " 0.8606572608429702,\n",
       " 0.4294814474048121,\n",
       " 1.0546863768901413,\n",
       " 1.0546863768901413,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.173259725585635,\n",
       " 0.5588341914362596,\n",
       " 0.7852014934912925,\n",
       " 0.3216874940452726,\n",
       " 0.09532019199023957,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.5828767483518849,\n",
       " 0.7636427028193846,\n",
       " 0.5480547961003056,\n",
       " 0.7528633074834307,\n",
       " 0.224672936021687,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6666281447957991,\n",
       " 0.8822160515148781,\n",
       " 0.6666281447957991,\n",
       " 0.91455423752274,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.8175396794991544,\n",
       " 0.6558487494598452,\n",
       " 0.7420839121474767,\n",
       " -0.21728227275242507,\n",
       " 0.12765837799810142,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.3349506556249442,\n",
       " 0.8283190748351084,\n",
       " 0.45104023807672,\n",
       " 0.6774075401317531,\n",
       " 0.3971432613969503,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.2379360976013587,\n",
       " 0.7097457261396148,\n",
       " 0.6019517727800754,\n",
       " 0.5696135867722135,\n",
       " 0.5480547961003056,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.1301421442418191,\n",
       " 0.5049372147564898,\n",
       " 0.5480547961003056,\n",
       " 0.7744220981553386,\n",
       " 0.10609958732619353,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.2893493080374107,\n",
       " 1.0331275862182334,\n",
       " -0.37897320279173435,\n",
       " 0.4941578194205358,\n",
       " 0.3971432613969503,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.23545233135764096,\n",
       " 0.7636427028193846,\n",
       " 0.2031141453497791,\n",
       " 0.12765837799810142,\n",
       " 0.06298200598237771,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.5803929821081675,\n",
       " 0.5696135867722135,\n",
       " 0.19233475001382513,\n",
       " 0.3109080987093186,\n",
       " 0.1815553546778712,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9900100048744177,\n",
       " 0.8390984701710623,\n",
       " 0.9576718188665558,\n",
       " -0.40053199346364227,\n",
       " 0.12765837799810142,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6558487494598452,\n",
       " 0.40792265673290423,\n",
       " 0.6774075401317531,\n",
       " 0.8822160515148781,\n",
       " 0.009085029302607944,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7528633074834307,\n",
       " 0.5049372147564898,\n",
       " 0.13843777333405538,\n",
       " -0.2603998540962409,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6342899587879373,\n",
       " 0.8606572608429702,\n",
       " 0.6450693541238912,\n",
       " 1.4535240043204376,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -0.4436495748074581,\n",
       " 0.9684512142025098,\n",
       " 0.4725990287486279,\n",
       " 0.903774842186786,\n",
       " 0.3109080987093186,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.9684512142025098,\n",
       " 0.7313045168115228,\n",
       " 0.13843777333405538,\n",
       " 0.688186935467707,\n",
       " 0.4294814474048121,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.7420839121474767,\n",
       " 0.8498778655070163,\n",
       " 0.2677905173655028,\n",
       " 0.6450693541238912,\n",
       " 0.5480547961003056,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 1.0331275862182334,\n",
       " 0.41870205206885813,\n",
       " 0.33246688938122654,\n",
       " 0.5803929821081675,\n",
       " 0.2893493080374107,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.6989663308036609,\n",
       " 0.7205251214755688,\n",
       " 0.44026084274076605,\n",
       " 0.6774075401317531,\n",
       " 0.224672936021687,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -0.40053199346364227,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " -1.2952218063478205,\n",
       " 0.45104023807672,\n",
       " 0.009085029302607944,\n",
       " 0.13843777333405538]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def z_score_normalize(lst):\n",
    "    normalized = []\n",
    "    for value in lst:\n",
    "        normalized_num = (value - np.mean(lst)) / np.std(lst)\n",
    "        normalized.append(normalized_num)\n",
    "    return normalized\n",
    "z_score_normalize(data1['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ldccLstm():\n",
    "    \n",
    "    ### 초기 설정\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        ### warning 메시지 무시\n",
    "        import warnings\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        \n",
    "        \n",
    "        ### aws python SDK 객체 생성 및 Amazon Forecast, Forecastquery, S3 에 연동, IAM 설정\n",
    "        self.fcst = ldcc_forecast_01_3.ldccForecast()\n",
    "        # region_name = ['서울': 'ap-northeast-2', '싱가포르': 'ap-southeast-1']\n",
    "        self.fcst.region_name = 'ap-northeast-2'\n",
    "        self.fcst.connect_aws()\n",
    "        self.fcst.iam_config()\n",
    "\n",
    "        \n",
    "        ### 인자 임포트 및 선언\n",
    "        with open('./bilstm_0609.yaml') as f:\n",
    "            self.argData = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "            # common\n",
    "            self.train_start_date = self.argData['common']['train_start_date']\n",
    "            self.train_end_date = self.argData['common']['train_end_date']\n",
    "            self.test_start_date = self.argData['common']['test_start_date']\n",
    "            self.test_end_date = self.argData['common']['test_end_date']\n",
    "            self.modelName = self.argData['common']['modelName']\n",
    "            \n",
    "            # data_import\n",
    "            self.train_readS3BucketName = self.argData['data_import']['train_readS3BucketName']\n",
    "            self.train_readS3Key = self.argData['data_import']['train_readS3Key']  \n",
    "            self.rel_readS3BucketName = self.argData['data_import']['rel_readS3BucketName']\n",
    "            self.rel_readS3Key = self.argData['data_import']['rel_readS3Key']\n",
    "            \n",
    "            # data_prep\n",
    "            self.n_steps_in = self.argData['data_prep']['n_steps_in']\n",
    "            self.n_steps_out = self.argData['data_prep']['n_steps_out']\n",
    "            self.features = self.argData['data_prep']['features']\n",
    "\n",
    "            # train_model\n",
    "            self.cell = self.argData['train_model']['cell']\n",
    "            self.epochs = self.argData['train_model']['epochs']\n",
    "            self.batch_size = self.argData['train_model']['batch_size']\n",
    "            self.verbose = self.argData['train_model']['verbose']\n",
    "            \n",
    "            # save_res\n",
    "            self.upload_to_s3_bool = self.argData['save_res']['upload_to_s3_bool']\n",
    "            self.save_dir = self.argData['save_res']['save_dir']\n",
    "            \n",
    "        \n",
    "    def data_prep(self):\n",
    "        \n",
    "        ## hstack 생성\n",
    "        # 피처별 어레이 데이터를 담을 딕셔너리 선언\n",
    "        feat_dict = {}\n",
    "        \n",
    "        # 피처가 아닌 칼럼 제거\n",
    "        column_list = self.merged_df.columns.drop(['timestamp', 'item_id'])\n",
    "        \n",
    "        # 각 피처 별로 어레이 타입으로 딕셔너리 구성 후, hstack으로 합치기 \n",
    "        for column_name in column_list:\n",
    "            feat_dict['%s' %column_name] = array(\n",
    "                self.merged_df['%s' %column_name]).reshape(\n",
    "                (len(self.merged_df['%s' %column_name]),1))\n",
    "        \n",
    "        self.raw_dataset = hstack(feat_dict.values())\n",
    "        \n",
    "        print('### hstack 생성')\n",
    "        for i in (0, 1, 2, 3, -3, -2, -1):\n",
    "            print('# hstack[%s]' %i)\n",
    "            print(self.raw_dataset[i])\n",
    "            print('\\n')        \n",
    "        print('\\n\\n\\n')\n",
    "    \n",
    "    \n",
    "        ## 시퀀스 쪼개기\n",
    "        # X, y로 쪼개기 위한 리스트 선언\n",
    "        X, y = [], []\n",
    "\n",
    "        # 시퀀스 길이만큼 1 step으로 수행\n",
    "        for i in range(len(self.raw_dataset)):\n",
    "            # X의 미만 위치, y의 이상 위치\n",
    "            end_ix = i + self.n_steps_in\n",
    "            # y의 미만 위치\n",
    "            out_end_ix = end_ix + self.n_steps_out\n",
    "            # y의 미만 위치가 시퀀스 길이를 넘으면 종료\n",
    "            if out_end_ix > len(self.raw_dataset):\n",
    "                break\n",
    "            # 시퀀스에서 multistep으로 X, y를 쪼개기\n",
    "            x_seq, y_seq = self.raw_dataset[i:end_ix], self.raw_dataset[end_ix:out_end_ix, -1]\n",
    "            X.append(x_seq)\n",
    "            y.append(y_seq)\n",
    "\n",
    "        self.X = array(X)\n",
    "        self.y = array(y)\n",
    "        \n",
    "        self.train_X = self.X[4:]\n",
    "        self.train_y = self.y[4:]\n",
    "        self.val_X = self.X[:4]\n",
    "        self.val_y = self.y[:4]\n",
    "        \n",
    "        print('### sequence 쪼개기')\n",
    "        for i in (0, 1, -2, -1):\n",
    "            print('# train X[%s]' %i)\n",
    "            print(self.train_X[i])\n",
    "            print('# train y[%s]' %i)\n",
    "            print(self.train_y[i])            \n",
    "            print('\\n')        \n",
    "            \n",
    "        for i in (0, 1, -2, -1):\n",
    "            print('# validation X[%s]' %i)\n",
    "            print(self.val_X[i])\n",
    "            print('# validation y[%s]' %i)\n",
    "            print(self.val_y[i])            \n",
    "            print('\\n')              \n",
    "        print('\\n\\n\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### 모델 학습\n",
    "    def train_model(self):        \n",
    "        # 모델 정의                \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Bidirectional(LSTM(self.cell, activation='relu'), input_shape=(self.n_steps_in, self.n_features)))\n",
    "        self.model.add(Dense(self.n_steps_out))\n",
    "        self.model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "        print('\\n\\n')\n",
    "\n",
    "        # 모델 fit\n",
    "        print('### model 학습')\n",
    "        hist = self.model.fit(self.train_X, self.train_y, \n",
    "                              validation_data=(self.val_X, self.val_y), \n",
    "                              epochs=self.epochs, \n",
    "                              batch_size = self.batch_size,\n",
    "                              verbose=self.verbose)\n",
    "        \n",
    "        fig, loss_ax = plt.subplots()\n",
    "\n",
    "        acc_ax = loss_ax.twinx()\n",
    "\n",
    "        loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "        loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "        acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "        acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')        \n",
    "        \n",
    "        loss_ax.set_xlabel('epoch')\n",
    "        loss_ax.set_ylabel('loss')\n",
    "        acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "        loss_ax.legend(loc='upper left')\n",
    "        acc_ax.legend(loc='lower left')\n",
    "        \n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "    def run_pred(self):\n",
    "        self.test_start_date = datetime.datetime.strptime(self.test_start_date, '%Y-%m-%d')           \n",
    "        self.test_end_date = datetime.datetime.strptime(self.test_end_date, '%Y-%m-%d')         \n",
    "        ## input_df 선언\n",
    "        input_start_date = self.test_start_date + datetime.timedelta(days=-(self.n_steps_in+3))\n",
    "        print('input_start_date: ', input_start_date)\n",
    "        input_end_date = self.test_start_date + datetime.timedelta(days=-1)\n",
    "        self.input_df = self.merged_df[\n",
    "            (self.merged_df['timestamp'] >= input_start_date) \n",
    "            &\n",
    "            (self.merged_df['timestamp'] <= input_end_date)\n",
    "        ]\n",
    "        print('### input_df 선언')        \n",
    "        print('# input_df shape')\n",
    "        print(self.input_df.shape)\n",
    "        print()\n",
    "        print('# input_df head')\n",
    "        print(self.input_df.head())\n",
    "        print()\n",
    "        print('# input_df tail')\n",
    "        print(self.input_df.tail())\n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "        ## input_x_seq 선언\n",
    "        # hstack 생성\n",
    "        # 피처별 어레이 데이터를 담을 딕셔너리 선언\n",
    "        feat_dict = {}\n",
    "        # 피처가 아닌 칼럼 제거\n",
    "        column_list = self.input_df.columns.drop(['timestamp', 'item_id'])\n",
    "        # 각 피처 별로 어레이 타입으로 딕셔너리 구성 후, hstack으로 합치기 \n",
    "        for column_name in column_list:\n",
    "            feat_dict['%s' %column_name] = array(\n",
    "                self.input_df['%s' %column_name]).reshape(\n",
    "                (len(self.input_df['%s' %column_name]),1))\n",
    "        self.input_raw_dataset = hstack(feat_dict.values())\n",
    "        print('### hstack 생성')\n",
    "        print('# hstack[0]')\n",
    "        print(self.input_raw_dataset[0])\n",
    "        print('\\n\\n\\n')\n",
    "        # 시퀀스로 생성        \n",
    "#         self.input_x_seq = array(self.input_raw_dataset).astype(np.int64)\n",
    "#         self.input_x_seq = self.input_x_seq.reshape(1,self.input_x_seq.shape[0],self.input_x_seq.shape[1])\n",
    "        self.input_x_seq = array(self.input_raw_dataset)\n",
    "        self.input_x_seq = self.input_x_seq.reshape(1,self.input_x_seq.shape[0],self.input_x_seq.shape[1])\n",
    "        print('### input_x 선언')\n",
    "        print('# input_x_seq shape')\n",
    "        print(self.input_x_seq.shape)\n",
    "        print('\\n') \n",
    "        print('# input_x_seq')\n",
    "        print(self.input_x_seq)\n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "        \n",
    "        ## 예측 수행\n",
    "        self.yhat = self.model.predict(self.input_x_seq, verbose=0).astype(np.int64)      \n",
    "        print('### 예측 수행')\n",
    "        print('# yhat')\n",
    "        print(self.yhat)\n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "        \n",
    "        ## rst_df 생성\n",
    "        # rst_df 1일 간격 날짜 변수 선언\n",
    "        rst_date_var = self.test_start_date\n",
    "        # 날짜를 입력할 리스트\n",
    "        rst_date_list = []\n",
    "        \n",
    "        while rst_date_var != self.test_end_date + datetime.timedelta(days=1):\n",
    "            rst_date_list.append(rst_date_var)\n",
    "            rst_date_var += datetime.timedelta(days=1)\n",
    "        \n",
    "        self.rst_df = pd.DataFrame(rst_date_list, columns=['timestamp'])\n",
    "        \n",
    "        ## rst_df에 yhat 칼럼 추가\n",
    "        self.rst_df['yhat'] = self.yhat[0][3:]\n",
    "        print('### rst_df 생성')\n",
    "        print('# rst_df')\n",
    "        print(self.rst_df)        \n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "        ## y가 있다면 rst_df에 label 칼럼 선언               \n",
    "        if self.target_df.iloc[-1,:]['timestamp'] > self.test_end_date:\n",
    "            self.label = self.target_df[\n",
    "                (self.target_df['timestamp'] >= self.test_start_date) \n",
    "                &\n",
    "                (self.target_df['timestamp'] <= self.test_end_date)\n",
    "            ][['target_value']]\n",
    "            \n",
    "            self.rst_df['label'] = list(self.label.target_value)\n",
    "            \n",
    "            print('### rst_df에 label 칼럼 추가')        \n",
    "            print('# label')\n",
    "            print(self.label)\n",
    "            print('\\n')\n",
    "            print('# rst_df')\n",
    "            print(self.rst_df)\n",
    "            print('\\n\\n\\n')            \n",
    "        else:\n",
    "            print('### label_df 선언')        \n",
    "            print('- 예측하고자 하는 기간의 실제값이 없으므로 label_df 선언 X')\n",
    "            print('# rst_df')\n",
    "            print(self.rst_df)            \n",
    "            print('\\n\\n\\n')\n",
    "\n",
    "\n",
    "    ### 라인그래프 시각화\n",
    "    def visualize_rst(self):\n",
    "        figure, ((ax1)) = plt.subplots(nrows=1, ncols=1)\n",
    "        figure.set_size_inches(18,8)\n",
    "\n",
    "        #legend list 선언\n",
    "        legend_list = []    \n",
    "\n",
    "        col_list = list(self.rst_df.columns)\n",
    "        col_list.remove('timestamp')\n",
    "        for line in col_list:\n",
    "            sns.lineplot(x='timestamp', \n",
    "                         y='%s' %line, \n",
    "                         data=self.rst_df, \n",
    "                         linewidth=4,\n",
    "                         label='big',\n",
    "                         ax=ax1\n",
    "                        )\n",
    "\n",
    "        # legend list 붙이기\n",
    "        legend_list.append('lunch' + ' ' + line)\n",
    "\n",
    "        # legend 생성\n",
    "        plt.legend(title='Line', loc='upper right', \n",
    "                   fontsize='x-large', title_fontsize='50', \n",
    "                   labels=legend_list)                        \n",
    "\n",
    "        # x, y limit 설정    \n",
    "        xlim = [self.rst_df['timestamp'][0], self.rst_df['timestamp'][-1:]]\n",
    "        ax1.set_xlim(xlim)    \n",
    "        ylim = [0,600]\n",
    "        ax1.set_ylim(ylim)\n",
    "\n",
    "        # x, y 라벨 이름, 크기\n",
    "        ax1.set_xlabel('Date',fontsize=40);\n",
    "        ax1.set_ylabel('Count',fontsize=40);                \n",
    "\n",
    "        # major tick 폰트 사이즈 설정\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=30)\n",
    "\n",
    "\n",
    "        # figure를 변수로 선언\n",
    "        self.figure = figure\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### error metrics 계산        \n",
    "    def error_metric(self):\n",
    "        \n",
    "        # y가 있다면\n",
    "        if self.target_df.iloc[-1,:]['timestamp'] > self.test_end_date:\n",
    "\n",
    "            ## RMSE\n",
    "            label = self.rst_df['label']\n",
    "            yhat = self.rst_df['yhat']\n",
    "            self.rmse = mean_squared_error(label, yhat)**0.5\n",
    "            print('### RMSE')\n",
    "            print(self.rmse)\n",
    "            print('\\n\\n')\n",
    "\n",
    "            ## MAPE\n",
    "            # 타우가 0.5일 때\n",
    "            # 분자 리스트 선언\n",
    "            numer_list = []\n",
    "            for i in range(0, len(list(self.rst_df))):\n",
    "                # 실제값 - 예측값 \n",
    "                abs_sub_val = abs(list(yhat)[i] - list(label)[i])                \n",
    "            \n",
    "                numer_list.append(abs_sub_val)\n",
    "            \n",
    "            total_numerator = sum(numer_list)\n",
    "            total_denominator = sum(list(label))\n",
    "            \n",
    "            self.mape = 2 * (total_numerator / total_denominator)\n",
    "            \n",
    "            print('### MAPE by AWS')\n",
    "            print(self.mape)\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            ## error_metric_df\n",
    "            error_list = []\n",
    "            error_list.append(self.modelName)\n",
    "            error_list.append(self.rmse)\n",
    "            error_list.append(self.mape)\n",
    "            error_list\n",
    "            \n",
    "            self.error_df = pd.DataFrame([error_list], \n",
    "                                    columns=['model_name',\n",
    "                                            'rmse',\n",
    "                                            'mape'])\n",
    "            \n",
    "            print('### error_df 생성')\n",
    "            print(self.error_df)\n",
    "            print('\\n\\n\\n')\n",
    "\n",
    "        else:\n",
    "            print('예측하고자 하는 구간의 실제값이 없으므로 error_metric 생략')\n",
    "            print('\\n\\n\\n')\n",
    "            pass\n",
    "        \n",
    "        return True\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ### 0. convlstm 객체 생성\n",
    "    ldcclstm = ldccLstm()    \n",
    "    \n",
    "    ### 2. 데이터 전처리\n",
    "    ldcclstm.data_prep()\n",
    "    \n",
    "    ### 3. 모델 학습\n",
    "    ldcclstm.train_model()\n",
    "    \n",
    "    ### 4. 예측 수행\n",
    "    ldcclstm.run_pred()\n",
    "\n",
    "    ### 6. 에러 메트릭 생성\n",
    "    ldcclstm.error_metric()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 16)\n",
      "(67, 16)\n",
      "(601, 1)\n",
      "(67, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=pd.read_csv('input2_daysin.csv')\n",
    "y=X[['target_value']]\n",
    "X=pd.concat([X[X.columns.difference(['weekday','timestamp','target_value'])], pd.get_dummies(X['weekday'])],axis=1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "y=scaler.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터, 테스트 데이터로 나누기 전에 fit과 transform 으로 변환. fit_transform() 도 무방. \n",
    "# scale된 iris_data로 학습과 테스트 데이터를 나눔."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 1, 16)\n",
      "(67, 1, 16)\n",
      "(601, 1)\n",
      "(67, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape((-1,1,16))\n",
    "X_test=X_test.reshape((-1,1,16))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "# (1395, 49, 1)\n",
    "# (599, 49, 1)\n",
    "# (1395, 46)\n",
    "# (599, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 2/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 3/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 4/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 5/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 6/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 7/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 8/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 9/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 10/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 11/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 12/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 13/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 14/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 15/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 16/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 17/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 18/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 19/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 20/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 21/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 22/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 23/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 24/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 25/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 26/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 27/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 28/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 29/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 30/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 31/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 32/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 33/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 34/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 35/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 36/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 37/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 38/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 39/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 40/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 41/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 42/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 43/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 44/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 45/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 46/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 47/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 48/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 49/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 50/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 51/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 52/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 53/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 54/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 55/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 56/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 57/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 58/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 59/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 60/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 61/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 62/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 63/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 64/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 65/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 66/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 67/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 68/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 69/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 70/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 71/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 72/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 73/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 74/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 75/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 76/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 77/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 78/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 79/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 80/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 81/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 82/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 83/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 84/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 85/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 86/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 87/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 88/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 89/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 90/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 91/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 92/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 93/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 94/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 95/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 96/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 97/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 98/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 99/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 100/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 101/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 102/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 103/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 104/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 105/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 106/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 107/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 108/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 109/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 110/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 111/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 112/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 113/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 114/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 115/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 116/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 117/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 118/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 119/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 120/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 121/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 122/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 123/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 124/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 125/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 126/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 127/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 128/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 129/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 130/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 131/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 132/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 133/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 134/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 135/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 136/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 137/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 138/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 139/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 140/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 141/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 142/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 143/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 144/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 145/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 146/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 147/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 148/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 149/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 150/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 151/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 152/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 153/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 154/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 155/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 156/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 157/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 158/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 159/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 160/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 161/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 162/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 163/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 164/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 165/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 166/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 167/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 168/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 169/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 170/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 171/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 172/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 173/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 174/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 175/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 176/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 177/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 178/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 179/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 180/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 181/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 182/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 183/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 184/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 185/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 186/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 187/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 188/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 189/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 190/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 191/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 192/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 193/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 194/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 195/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 196/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 197/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 198/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 199/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "Epoch 200/200\n",
      "13/13 - 0s - loss: 0.0000e+00 - accuracy: 0.0017\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f325f193400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7358378701097333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Activation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(70, return_sequences = False), input_shape = (1,16)))\n",
    "# model.add(Bidirectional(LSTM(20, return_sequences = False), input_shape = (1,16)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "\n",
    "# model = KerasClassifier(build_fn = bidirectional_lstm, epochs = 200, batch_size = 50, verbose = 2)\n",
    "model.fit(X_train, y_train,epochs = 200, batch_size = 50, verbose = 2)\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_ = np.argmax(y_test, axis = 1)\n",
    "print(accuracy_score(y_pred, y_test_)) \n",
    "RMSE = mean_squared_error(y_test, y_pred)**0.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Activation\n",
    "\n",
    "# train_X=pd.concat([train[train.columns.difference(['weekday','timestamp','target_value'])] ,pd.get_dummies(train['weekday'])],axis=1)\n",
    "# train_X=scaler.fit_transform(train_X)\n",
    "# train_X=train_X.reshape(-1,1,16)\n",
    "# train_y=scaler.fit_transform(np.array(train['target_value']).reshape(-1,1)).reshape((-1,1))\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# val_X=pd.concat([test[test.columns.difference(['weekday','timestamp','target_value'])] ,pd.get_dummies(test['weekday'])],axis=1)\n",
    "# val_X=scaler.fit_transform(val_X)\n",
    "# val_X=val_X.reshape(-1,1,17)\n",
    "# val_y=scaler.fit_transform(np.array(test['target_value']).reshape(-1,1)).reshape((-1,1))\n",
    "\n",
    "# n_steps_in=7\n",
    "# n_steps_out=7\n",
    "# cell=8\n",
    "# n_features=len(train_X.columns)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True, activation='sigmoid'), input_shape=(16,1)))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "hist = model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=50, batch_size = 20)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.3 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
