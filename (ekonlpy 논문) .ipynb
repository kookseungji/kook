{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연합인포맥스 홈페이지 2014.01.01-2019.07.12 \n",
    "# '금리' 검색 결과 뉴스 크롤링 (날짜, title, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from urllib import parse\n",
    "\n",
    "class YonhapSpider(scrapy.Spider):\n",
    "    name = 'yonhap'\n",
    "    allowed_domains = ['news.einfomax.co.kr']\n",
    "    start_urls=[]\n",
    "    for i in range(4000):\n",
    "        i=str(i)\n",
    "        urls = 'https://www.yna.co.kr/search/index?query=%EA%B8%88%EB%A6%AC'\n",
    "        start_urls.append(urls)\n",
    "\n",
    "        def parse(self, response):\n",
    "             \n",
    "            for qu in response.css('ul'):\n",
    "                link=qu.css('a::attr(href)').get()\n",
    "                next_page = link\n",
    "            #if next_page is not None:\n",
    "                yield response.follow(next_page, callback=self.pse)    \n",
    "            \n",
    "        def pse(self, response):   \n",
    "            yield {\n",
    "                    'title': response.css('h1.tit-article::text').get(),\n",
    "                    'content': response.css('div.article::text').getall(),\n",
    "                    'date':response.css('div.share-info span.tt::text').getall()\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "yonhap=pd.read_csv('연합인포맥스_2011-2019.csv')\n",
    "yonhap['press']=' 연합인포맥스'\n",
    "yonhap.date=yonhap.date.str[4:14]\n",
    "yonhap['date']=yonhap['date'].apply(lambda x : x[:4]+x[5:7]+x[8:])\n",
    "yonhap['date']=pd.to_datetime(yonhap['date'])\n",
    "sep = '(끝)'\n",
    "yonhap['content']=yonhap['content'].apply(lambda x : x.lstrip('\\r\\n\\t').rstrip('\\r\\n\\t').rstrip('\\r\\n').rstrip('\\t\\t').rstrip('\\r\\n\\r\\n\\t\\t\\r\\n\\t\\t,\\r\\n\\r\\n\\t\\t\\'').split(sep, 1)[0])\n",
    "yonhap['content']=yonhap['content'].apply(lambda x :re.sub('\\(서울=연합인포맥스\\)','',x)).apply(lambda x :re.sub('\\(뉴욕=연합인포맥스\\)','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap['content']=yonhap['content'].apply(lambda x :re.sub('.+[가-힣]{2} \\=','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "def text2ngram(text):\n",
    "    mpck = MPCK()\n",
    "    bef_tokens = mpck.tokenize(text)\n",
    "    ngrams = mpck.ngramize(bef_tokens)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram=[]\n",
    "for i in range(120036):\n",
    "    strcat.(a[ngram][i],(text2ngram(yonhap['content'][i]))\n",
    "yonhap['ngram']=ngram            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoninfo1= pd.read_csv(\"연합인포맥스 ngram 2005-2010.csv\",index_col=0)\n",
    "yoninfo1['date']=pd.to_datetime(yoninfo1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap_info=yoninfo1.append(yonhap)\n",
    "yonhap_info= yonhap_info.reset_index(drop=True)\n",
    "yonhap_info= yonhap_info.sort_values(by='date')\n",
    "yonhap_info=yonhap_info.drop([140978,])\n",
    "col_list=['date','press','title','content','ngram']\n",
    "yonhap_info=yonhap_info[col_list]\n",
    "yonhap_info.to_csv(\"yonhap_info_2005-2019_전처리.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a=pd.read_csv(\"(완료)연합인포맥스_2005-2019_전처리.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "def text2ngram(text):\n",
    "    mpck = MPCK()\n",
    "    bef_tokens = mpck.tokenize(text)\n",
    "    return bef_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(101,140979):    \n",
    "    try:\n",
    "        a['ngram'][i]=a['ngram'][i]+\",\".join(text2ngram(a['content'][i]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e57fe7d9a686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'old_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'old_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# a.to_csv(\"(완료)연합인포맥스_2005-2019_전처리.csv\")\n",
    "call=pd.read_csv(\"callrate_ver5.csv\", index_col=0)\n",
    "call['date']=pd.to_datetime(call['date'])\n",
    "a['date'] = pd.to_datetime(a['date'])\n",
    "pd.merge(a,call,on='date',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap_and_call=pd.merge(a,call,on='date',how='outer')\n",
    "yonhap_and_call.to_csv(\"(완료)연합인포맥스_2005-2019_콜금리라벨까지.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yonhap= pd.read_csv(\"(완료)연합인포맥스_2005-2019_콜금리라벨까지.csv\", index_col=0)\n",
    "yonhap=yonhap.drop(['Unnamed: 0.1','updown','old_date','callrate','old_callrate','updown'],axis=1)\n",
    "call= pd.read_csv(\"my_callrate_ffill.csv\", index_col=0)\n",
    "call['date']=pd.to_datetime(call['date'])\n",
    "yonhap['date']=pd.to_datetime(yonhap['date'])\n",
    "call=call.drop(['callrate','old_date','old_callrate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap=pd.merge(yonhap,call,on='date',how='outer').sort_values(['date']).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap['n']=yonhap['ngram'].apply(lambda x : str(x).count(';'))\n",
    "yonhap=yonhap[yonhap['n']>15]\n",
    "yonhap['t/f']=yonhap['updown'].apply(lambda x : x in ('up','down','neutrality'))\n",
    "yonhap=yonhap[yonhap['t/f']==True]\n",
    "yonhap=yonhap.drop('t/f',axis=1)\n",
    "down확률=len(yonhap[yonhap['updown']=='down'])/len(yonhap) \n",
    "up확률=len(yonhap[yonhap['updown']=='up'])/len(yonhap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap['ngram']=yonhap['ngram'].apply(lambda x:re.sub('[가-힣]{1,8}\\/(JKS|JKC|JKG|JKO|JKB|JKV|JKQ|JC|JX|EP|EF|EC|ETN|ETM|XPN|XSN|XSV|XSA|XR|SF|SE|SSO|SSC|SC|SY|SH|SL|SN)(\\,?)','',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap.to_csv(\"(최종)연합인포맥스_2005-2019_콜금리라벨까지.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yonhap=pd.read_csv('(최종)연합인포맥스_2005-2019_콜금리라벨까지.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ls = []\n",
    "\n",
    "for i in range(len(yonhap)):\n",
    "    try:\n",
    "        test = yonhap['ngram'][i].replace(' ','').split(',') \n",
    "        temp_ls.extend(test) \n",
    "    except: \n",
    "        pass\n",
    "\n",
    "temp_df = pd.DataFrame(temp_ls, columns=['ngram']) \n",
    "final_df = pd.DataFrame(temp_df['ngram'].value_counts())\n",
    "final_df=final_df[final_df['ngram']>=15]\n",
    "final_df['index1'] = final_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap00=yonhap[yonhap['updown']=='up']\n",
    "import pandas as pd\n",
    "temp_l= []\n",
    "\n",
    "for i in range(len(yonhap)):\n",
    "    try:\n",
    "        test = yonhap00['ngram'][i].replace(' ','').split(',') \n",
    "        temp_l.extend(test) \n",
    "    except: \n",
    "        pass\n",
    "\n",
    "temp_dff = pd.DataFrame(temp_l, columns=['up_ngram']) \n",
    "final_dff = pd.DataFrame(temp_dff['up_ngram'].value_counts()) \n",
    "final_dff['index1'] = final_dff.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonhap0=yonhap[yonhap['updown']=='down']\n",
    "import pandas as pd\n",
    "temp= []\n",
    "\n",
    "for i in range(len(yonhap)):\n",
    "    try:\n",
    "        test = yonhap0['ngram'][i].replace(' ','').split(',') \n",
    "        temp.extend(test) \n",
    "    except: \n",
    "        pass\n",
    "\n",
    "temp_d = pd.DataFrame(temp, columns=['down_ngram']) \n",
    "final_d = pd.DataFrame(temp_d['down_ngram'].value_counts()) \n",
    "final_d['index1'] = final_d.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up=pd.merge(final_df,final_dff,how='outer')\n",
    "up['분자']=up['up_ngram']/len(temp_dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down=pd.merge(final_df,final_d,how='outer')\n",
    "down['분모']=down['down_ngram']/len(temp_d)\n",
    "down.drop('ngram',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "엄=pd.merge(up,down,how='outer',on='index1')\n",
    "엄['polarity']=엄['분자']/엄['분모']\n",
    "엄최종=엄[(엄['polarity']>1.3)|(엄['ploarity']<0.76)]\n",
    "엄최종.reset_index(drop=True)\n",
    "엄최종['hawk/dov']='hawkish'\n",
    "엄최종['hawk/dov']=엄최종[엄['polarity']<0.76]['hawk/dov'].replace('hawkish','dovish')\n",
    "엄최종.dropna()\n",
    "엄최종['hawk/dov']=엄최종['hawk/dov'].fillna('hawkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yonh=yonhap[yonhap['updown']=='neutrality']\n",
    "import pandas as pd\n",
    "temp= []\n",
    "\n",
    "for i in range(len(yonhap)):\n",
    "    try:\n",
    "        test = yonh['ngram'][i].replace(' ','').split(',') \n",
    "        temp.extend(test) \n",
    "    except: \n",
    "        pass\n",
    "\n",
    "temp_ = pd.DataFrame(temp, columns=['neu_ngram']) \n",
    "final_ = pd.DataFrame(temp_['neu_ngram'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연합뉴스 네이버 2005.05-2017.12.31 \n",
    "# '금리' 검색 결과 뉴스 크롤링 (날짜, title, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from datetime import timedelta, date\n",
    "start_date = date(2005, 1, 1)\n",
    "end_date = date(2005, 1, 16)\n",
    "cnt_per_page = 10\n",
    "keyword='�ݸ�'\n",
    "url_format = \"https://search.naver.com/search.naver?&where=news&query={1}&sm=tab_pge&sort=0&photo=0&field=0&reporter_article=&pd=3&ds={0}&de={0}&docid=&nso=so:r,p:from{0}to{0},a:all&mynews=1&cluster_rank=1&start={2}&refresh_start=0\"\n",
    "\n",
    "class YonhapSpider(scrapy.Spider):\n",
    "    name = 'yonhap2'\n",
    "    allowed_domains = ['naver.com','yna.co.kr']\n",
    "    start_urls = []\n",
    "    def daterange(start_date, end_date):\n",
    "        for n in range(int ((end_date - start_date).days)):\n",
    "            yield start_date + timedelta(n)\n",
    "       \n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        start_urls.append(url_format.format(single_date.strftime(\"%Y%m%d\"),keyword, 1))\n",
    "        \n",
    "    def parse(self, response):    \n",
    "        for qu in response.css('ul.type01'):\n",
    "            link=qu.css('a::attr(href)').get()        \n",
    "            next_page = link\n",
    "            print(next_page)\n",
    "    #         yield response.follow(next_page, callback=self.pse)\n",
    "                    \n",
    "    # def pse(self, response):   \n",
    "    #     yield {\n",
    "    #             'title': response.css('h1.tit-article::text').get(),\n",
    "    #             'content': response.css('div.article::text').get(),\n",
    "    #             'date':response.css('div.share-info span.tt::text').get()\n",
    "    #           }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연합뉴스 2010-2014 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "yon=pd.read_csv('연합뉴스_2010-2014.csv')\n",
    "yon['press']=' 연합뉴스'\n",
    "yon['date']=yon['date'].astype('str')\n",
    "yon=yon.drop('link',axis=1)\n",
    "yon['content'] = yon['content'].apply(lambda x: re.sub(\"\\w*\\@.+\",'',x,1))\n",
    "yon['content'] = yon['content'].apply(lambda x: re.sub(\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\",'',x,1))\n",
    "yon['date']=pd.to_datetime(yon['date'])\n",
    "#yon['content']=yon['content'].apply(lambda x: re.sub(\".+['기자']{2}\\=|.+['기자']{2} \\=\",'',x,1))\n",
    "# sep = '(끝)'\n",
    "# yonhap['content']=yonhap['content'].apply(lambda x : x.lstrip('\\r\\n\\t').rstrip('\\r\\n\\t').rstrip('\\r\\n').rstrip('\\t\\t').rstrip('\\r\\n\\r\\n\\t\\t\\r\\n\\t\\t,\\r\\n\\r\\n\\t\\t\\'').split(sep, 1)[0])\n",
    "# yonhap['content']=yonhap['content'].apply(lambda x :re.sub('\\(서울=연합인포맥스\\)','',x)).apply(lambda x :re.sub('\\(뉴욕=연합인포맥스\\)','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "def text2ngram(text):\n",
    "    mpck = MPCK()\n",
    "    bef_tokens = mpck.tokenize(text)\n",
    "    ngrams = mpck.ngramize(bef_tokens)\n",
    "    return ngrams\n",
    "n_gram=[]\n",
    "for i in range(11732):\n",
    "    n_gram.append(text2ngram(yon['content'][i]))\n",
    "yon['ngram']=n_gram\n",
    "yon.to_csv(\"yon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연합뉴스 2015,2016,2017 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "yon1=pd.read_csv('연합뉴스_2015.csv')\n",
    "yon1['press']='연합뉴스'\n",
    "yon1=yon1.drop([1,])\n",
    "yon1['date']=yon1['date'].astype('str')\n",
    "yon1=yon1.drop('link',axis=1)\n",
    "yon1['content'] = yon1['content'].apply(lambda x: re.sub(\"\\w*\\@.+\",'',x,1))\n",
    "yon1['content'] = yon1['content'].apply(lambda x: re.sub(\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\",'',x,1))\n",
    "yon1['date']=pd.to_datetime(yon1['date'])\n",
    "yon1= yon1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yon1['content']=yon1['content'].apply(lambda x: re.sub('.+[가-힣]{2} \\=|.+[가-힣]{2}\\=','',x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "def text2ngram(text):\n",
    "    mpck = MPCK()\n",
    "    bef_tokens = mpck.tokenize(text)\n",
    "    ngrams = mpck.ngramize(bef_tokens)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram=[]\n",
    "for i in range(979):\n",
    "    n_gram.append(text2ngram(yon1['content'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yon1['ngram']=n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yon = pd.read_csv(\"yon.csv\",index_col=0)\n",
    "yon['date']=pd.to_datetime(yon['date'])\n",
    "yon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yon2010_2015=yon.append(yon1)\n",
    "yon2010_2015= yon2010_2015.reset_index(drop=True)\n",
    "yon2010_2015.to_csv(\"연합뉴스2010_2015ngram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "y2016['press']='연합뉴스'\n",
    "# yon2=yon2.drop([1,])\n",
    "y2016['date']=y2016['date'].astype('str')\n",
    "y2016=y2016.drop('link',axis=1)\n",
    "y2016['content'] = y2016['content'].apply(lambda x: re.sub(\"\\w*\\@.+\",'',x,1))\n",
    "y2016['content'] = y2016['content'].apply(lambda x: re.sub(\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\",'',x,1))\n",
    "y2016['date']=pd.to_datetime(y2016['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.read_csv(\"연합뉴스2010_2015ngram.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2016=pd.read_csv(\"연합뉴스_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "def text2ngram(text):\n",
    "    mpck = MPCK()\n",
    "    bef_tokens = mpck.tokenize(text)\n",
    "    ngrams = mpck.ngramize(bef_tokens)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram=[]\n",
    "for i in range(1313):\n",
    "    n_gram.append(text2ngram(y2016['content'][i]))\n",
    "y2016['ngram']=n_gram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2017=pd.read_csv(\"연합뉴스_2017.csv\")\n",
    "y2017['press']='연합뉴스'\n",
    "# y2017=y2017.drop([1,])\n",
    "y2017['date']=y2017['date'].astype('str')\n",
    "y2017=y2017.drop('link',axis=1)\n",
    "y2017['content'] = y2017['content'].apply(lambda x: re.sub(\"\\w*\\@.+\",'',x,1))\n",
    "y2017['content'] = y2017['content'].apply(lambda x: re.sub(\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\",'',x,1))\n",
    "y2017['date']=pd.to_datetime(y2017['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram=[]\n",
    "for i in range(len(y2017['content'])):\n",
    "    n_gram.append(text2ngram(y2017['content'][i]))\n",
    "y2017['ngram']=n_gram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2016_2017=y2016.append(y2017)\n",
    "y2016_2017= y2016_2017.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2010_2015=pd.read_csv(\"연합뉴스2010_2015ngram.csv\",index_col=0)\n",
    "y2010_2015['date']=pd.to_datetime(y2010_2015['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2010_2017=y2010_2015.append(y2016_2017)\n",
    "y2010_2017=y2010_2017.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2005_2007=pd.read_csv(\"연합뉴스2005-2007.csv\")\n",
    "y2008_2009=pd.read_csv(\"연합뉴스2008-2009.csv\")\n",
    "y2005_2007['press']='연합뉴스'\n",
    "y2005_2007['date']=y2005_2007['date'].astype('str')\n",
    "y2005_2007=y2005_2007.drop('link',axis=1)\n",
    "y2005_2007['content'] = y2005_2007['content'].apply(lambda x: re.sub(\"\\w*\\@.+\",'',x,1))\n",
    "y2005_2007['content'] = y2005_2007['content'].apply(lambda x: re.sub(\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\",'',x,1))\n",
    "y2005_2007['date']=pd.to_datetime(y2005_2007['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y2008_2009' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-326af872698d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'press'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'연합뉴스'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my2008_2009\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my2008_2009\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'link'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\w*\\@.+\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my2008_2009\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y2008_2009' is not defined"
     ]
    }
   ],
   "source": [
    "y2008_2009['press']='연합뉴스'\n",
    "y2008_2009['date']=y2008_2009['date'].astype('str')\n",
    "y2008_2009=y2008_2009.drop('link',axis=1)\n",
    "y2008_2009['content'] = y2008_2009['content'].apply(lambda x: re.sub(\"\\w*\\@.+\",'',x,1))\n",
    "y2008_2009['content'] = y2008_2009['content'].apply(lambda x: re.sub(\"\\([가-힣].=연합인포맥스\\)|\\([가-힣].=연합뉴스\\)\",'',x,1))\n",
    "y2008_2009['date']=pd.to_datetime(y2008_2009['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram=[]\n",
    "for i in range(4432):\n",
    "    n_gram.append(text2ngram(y2008_2009['content'][i]))\n",
    "y2008_2009['ngram']=n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram=[]\n",
    "for i in range(5262):\n",
    "    n_gram.append(text2ngram(y2005_2007['content'][i]))\n",
    "y2005_2007['ngram']=n_gram\n",
    "y2005_2007.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2005_2009=y2005_2007.append(y2008_2009)\n",
    "y2005_2009=y2005_2009.reset_index(drop=True)\n",
    "y2005_2017=y2005_2009.append(y2010_2017)\n",
    "y2005_2017=y2005_2017.reset_index(drop=True)\n",
    "y2005_2017.to_csv(\"(완료)연합뉴스2005-2017_ngram.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사록 어조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "yonhap=pd.read_csv('(최종)모든자료date_ngram_label.csv',index_col=0)\n",
    "yonhap['ngram'] = yonhap['ngram'].apply(lambda x:re.sub('[가-힣]{1,8}\\/(JKS|JKC|JKG|JKO|JKB|JKV|JKQ|JC|JX|EP|EF|EC|ETN|ETM|XPN|XSN|XSV|XSA|XR|SF|SE|SSO|SSC|SC|SY|SH|SL|SN)(\\,?)','',str(x),1))\n",
    "yonhap['ngram'] = yonhap['ngram'].apply(lambda x: re.sub('\\s+[가-힣]{1,8}\\/(JKS|JKC|JKG|JKO|JKB|JKV|JKQ|JC|JX|EP|EF|EC|ETN|ETM|XPN|XSN|XSV|XSA|XR|SF|SE|SSO|SSC|SC|SY|SH|SL|SN)(\\S*|\\,)','',str(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_rock_raw = pd.read_csv('(완성)_금통위_의사록.csv', encoding='utf-8', index_col=0)\n",
    "dr_rock = dr_rock_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_polar = pd.read_csv('df_hawk_dov_new.csv', encoding='utf-8', index_col = 0)\n",
    "our_polar = our_polar.reset_index(drop=False)\n",
    "our_polar[our_polar.ngram.str.contains(';')][our_polar['hawk/dov']=='dovish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hawk = our_polar[our_polar['hawk/dov'] == 'hawkish']\n",
    "hawk_list = list(hawk['ngram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dov = our_polar[our_polar['hawk/dov'] == 'dovish']\n",
    "dov = dov.reset_index(drop=True)\n",
    "dov_list = list(dov['ngram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ls = [] # 빈리스트 생성\n",
    "for i, row in dr_rock.iterrows(): # 사용할 데이터프레임의 길이로 for문 돌리기\n",
    "    test = row['ngram'].split(',') # 컬럼이름 ngram의 i 번째를 split\n",
    "    temp_ls.extend(test) # 빈 리스트에 한번에 추가\n",
    "    if i%1000 == 0 : # %: 나머지, 1000개마다 프린트\n",
    "        print('{}/{}'.format(i, dr_rock.shape[0]))\n",
    "temp_df = pd.DataFrame(temp_ls, columns=['ngram']) # 새로운 데이터프레임 생성\n",
    "df_up1 = pd.DataFrame(temp_df['ngram'].value_counts()) # value_counts사용\n",
    "df_up1 = df_up1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_rock['sentence_score'] = 0\n",
    "dr_rock['sentence_score'] = dr_rock['sentence_score'].astype('float') \n",
    "\n",
    "for idx,val in enumerate(dr_rock['ngram']):\n",
    "    word_list = val.replace(' ','').split(',')\n",
    "    h_count = 0\n",
    "    d_count = 0\n",
    "    sentence_score = 0\n",
    "    \n",
    "    for i in word_list:\n",
    "        if i in hawk_list:\n",
    "            h_count += 1\n",
    "            \n",
    "        elif i in dov_list:\n",
    "            d_count += 1\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    bunja = float(h_count - d_count)\n",
    "    bunmo = float(h_count + d_count)\n",
    "    \n",
    "    try:\n",
    "        sentence_score = float(bunja / bunmo)\n",
    "        dr_rock['sentence_score'][idx] = sentence_score\n",
    "        \n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivision\")\n",
    "        dr_rock['sentence_score'][idx] = 0\n",
    "    \n",
    "    \n",
    "    if idx % 100 == 0 :\n",
    "        print('현재 인덱스 : ',idx,'카운트 : ', sentence_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_save = dr_rock.copy()\n",
    "dr_save = dr_save.reset_index(drop=True)\n",
    "dr_save[dr_save['date']=='2005-10-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_score = pd.DataFrame(columns=['date', 'score'])\n",
    "dr_score['score'] = dr_score['score'].astype('float')\n",
    "\n",
    "for i in date_list:\n",
    "    one_dr = dr_save[dr_save['date'] == i]\n",
    "    pos_sentence = len(one_dr[one_dr['sentence_score'] >= 0])\n",
    "    neg_sentence = len(one_dr[one_dr['sentence_score'] <0])\n",
    "    \n",
    "    \n",
    "    bunmo = pos_sentence + neg_sentence\n",
    "    bunja = pos_sentence - neg_sentence\n",
    "    \n",
    "    try:\n",
    "        score = float(bunja / bunmo)\n",
    "        dr_score = dr_score.append(pd.DataFrame([[i, score]], columns=['date','score']), ignore_index = True)\n",
    "        \n",
    "    except ZeroDivisionError:\n",
    "        print(\"ZeroDivision\")\n",
    "        dr_score = dr_score.append(pd.DataFrame([[i, 0]], columns=['date','score']), ignore_index = True)\n",
    "\n",
    "dr_score = dr_score.sort_values(['date'], ascending=[True])\n",
    "dr_score= dr_score.reset_index(drop=True)\n",
    "dr_score['date'] = pd.to_datetime(dr_score['date'])\n",
    "dr_score = dr_score.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = list(set(dr_rock['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dr_score['score'])\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)\n",
    "plt.ylim(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_raw = pd.read_csv('기준금리2005_2019.csv', encoding='utf-8',index_col=0)\n",
    "call_copy = call_raw.copy()\n",
    "call_copy['date'] = pd.to_datetime(call_copy['date'])\n",
    "call_copy = call_copy.sort_values(['date'], ascending=[True])\n",
    "call_copy['BMR'] = (call_copy['BMR']-call_copy['BMR'].min())/(call_copy['BMR'].max()-call_copy['BMR'].min())\n",
    "call_copy = call_copy.set_index('date')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(call_copy['BMR'])\n",
    "plt.plot(dr_score['score'])\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "call_copy['BMR']=preprocessing.MinMaxScaler().fit_transform(call_copy['BMR'].values.reshape(-1,1))\n",
    "dr_score['score']=preprocessing.MinMaxScaler().fit_transform(dr_score['score'].values.reshape(-1,1))\n",
    "call_copy = call_copy.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_call_raw= pd.read_csv('my_callrate_ffill.csv', encoding='utf-8', index_col = 0)\n",
    "my_call_copy = my_call_raw.copy()\n",
    "my_call_copy['date'] = pd.to_datetime(my_call_copy['date'])\n",
    "new_rate = my_call_copy.merge(call_copy, on ='date', how='left')\n",
    "news_rate = new_rate.fillna(method = 'bfill', axis = 0)\n",
    "news_rate = news_rate.drop('old_date', axis = 1).drop('callrate', axis = 1).drop('old_callrate', axis = 1).drop('updown', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'news_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-41e472117a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnews_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BMR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BMR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdr_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdr_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnews_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnews_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews_rate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'news_rate' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "news_rate['BMR']=preprocessing.MinMaxScaler().fit_transform(news_rate['BMR'].values.reshape(-1,1))\n",
    "dr_score['score']=preprocessing.MinMaxScaler().fit_transform(dr_score['score'].values.reshape(-1,1))\n",
    "news_rate['date'] = pd.to_datetime(news_rate['date'])\n",
    "news_rate = news_rate.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_rate['BMR'] = news_rate['BMR']-0.5\n",
    "dr_score['score'] = dr_score['score']-0.5\n",
    "news_rate['BMR'] = news_rate['BMR'] *2\n",
    "dr_score['score'] = dr_score['score'] *2\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(news_rate['BMR'])\n",
    "plt.plot(dr_score['score'])\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo=pd.merge(news_rate,dr_score,left_index=True,right_index=True)\n",
    "df6 = yo[['score','BMR']]\n",
    "df6.cor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
